{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- # Simplified Salary Prediction Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load Data ---\n",
    "# Make sure 'MultipleFiles/employees data set csv.csv' is in the correct path\n",
    "# relative to where your Jupyter Notebook is running, or provide the full path.\n",
    "file_path = 'MultipleFiles/employees data set csv.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(\"--- Data Preview ---\")\n",
    "print(data.head())\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Prepare Data ---\n",
    "\n",
    "# Drop unnecessary columns and those that cause data leakage\n",
    "# 'No' is just an ID. 'Start Date' is covered by 'Years'.\n",
    "# 'Monthly Salary' is too similar to 'Annual Salary' (our target)\n",
    "data_cleaned = data.drop(['No', 'Start Date', 'Monthly Salary'], axis=1)\n",
    "\n",
    "# Define what we want to predict (Annual Salary) and our features\n",
    "target_column = 'Annual Salary'\n",
    "y = data_cleaned[target_column] # The salary we want to predict\n",
    "X = data_cleaned.drop(target_column, axis=1) # All other columns are features\n",
    "\n",
    "# Separate numerical and categorical features for processing\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print(f\"Features used for prediction: {X.columns.tolist()}\")\n",
    "print(f\"Target variable: {target_column}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Preprocessing Steps (Scaling and Encoding) ---\n",
    "\n",
    "# Create steps to prepare our data:\n",
    "# 1. Scale numerical features (e.g., 'Years', 'Job Rate')\n",
    "# 2. Convert categorical features (e.g., 'Gender', 'Department') into numbers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features), # Apply scaling to numbers\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features) # Apply one-hot encoding to categories\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cdce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Split Data for Training and Testing ---\n",
    "# We split our data to train the model on one part and test it on unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing data size: {X_test.shape[0]} samples\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Build and Train the Model (Random Forest) ---\n",
    "\n",
    "# We'll use a RandomForestRegressor, which is a powerful model for many tasks\n",
    "# The Pipeline combines preprocessing and the model into one step\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "\n",
    "print(\"--- Training the Random Forest Model ---\")\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a2b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Evaluate the Model ---\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate how well our model performed\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse) # Root Mean Squared Error (easier to understand than MSE)\n",
    "r2 = r2_score(y_test, predictions) # R-squared (how much variance is explained by the model)\n",
    "\n",
    "print(\"--- Model Evaluation Results ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9751c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Make a Prediction on New Data ---\n",
    "\n",
    "print(\"--- Predicting Salary for a New Employee ---\")\n",
    "\n",
    "# Create a new, imaginary employee's data\n",
    "# Make sure all feature columns are present, even if values are different\n",
    "new_employee_data = pd.DataFrame({\n",
    "    'First Name': ['New'],\n",
    "    'Last Name': ['Candidate'],\n",
    "    'Gender': ['Female'],\n",
    "    'Years': [3], # 3 years of experience\n",
    "    'Department': ['Marketing'],\n",
    "    'Country': ['United Arab Emirates'],\n",
    "    'Center': ['Main'],\n",
    "    'Job Rate': [4.0],\n",
    "    'Sick Leaves': [1],\n",
    "    'Unpaid Leaves': [0],\n",
    "    'Overtime Hours': [5]\n",
    "})\n",
    "\n",
    "print(\"New Employee Details:\")\n",
    "print(new_employee_data)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Use our trained model to predict their annual salary\n",
    "predicted_salary = model_pipeline.predict(new_employee_data)\n",
    "\n",
    "print(f\"Predicted Annual Salary: ${predicted_salary[0]:,.2f}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Conclusion ---\n",
    "print(\"--- Conclusion ---\")\n",
    "print(\"We successfully built a simplified salary prediction model.\")\n",
    "print(\"The model was trained on employee data and can now estimate annual salaries\")\n",
    "print(\"based on various employee attributes.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
